---
title: "MovieLens Project"
author: "Daniel Cash (dwcash)"
date: "April 26, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#MovieLens: Introduction
On October 2006, Netflix offered a challenge to improve their recommendation algorithm by 10% and win a million dollars. The Netflix data is not publicly available, but thanks to the GroupLens research lab we have a similar kind of dataset to analyze. Only a small subset of the data is used, which is available in the dslabs package. The data has already been split into training and testing sets per the course instructions. The goal of this project is to predict the rating a user would give to a specific movie. This algorithm would allow us to provide relevant movie suggestions to users, in other words, a recommendation system. The loss function used is the residual mean squared error (RMSE) and the cut-off for full credit is to achieve a RMSE below or equal to 0.87750.
\newpage

#Methods and Analysis
Since the dataset provided was already in tidy format, no data cleaning was necessary. First, the composition of the dataset is analyzed to see if it is more sparse or dense. Of all the Netflix videos or shows I've watched I may have only rated once, if at all. If the average user is anything like me, there will be a lot of missing ratings.
```{r file download and dataset,echo=FALSE, results='hide', warning=FALSE, message=FALSE} 
#############################################################
# Create edx set, validation set, and submission file
#############################################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- read.table(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                      col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data

set.seed(1)
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set

validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set

removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)
```
```{r Install and load Packages, echo=FALSE, results='hide',message=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
library(knitr)
library(gridExtra)
```

###Unique users that provided ratings and how many unique movies were rated
```{r Unique, echo=FALSE}
edx %>% 
  summarize(n_users = n_distinct(userId),
            n_movies = n_distinct(movieId))
```

###Number of ratings in dataset
```{r length, echo=FALSE}
length(edx$rating)
```

The product of the two numbers is far greater than the rows in our dataset which shows that often users do not rate movies. We can visualize this by taking a random sample.

```{r Sparse Matrix, echo=FALSE}
users <- sample(unique(edx$userId), 100)
edx %>% filter(userId %in% users) %>% 
select(userId, movieId, rating) %>%
mutate(rating = 1) %>%
spread(movieId, rating) %>% select(sample(ncol(.), 100)) %>% 
as.matrix() %>% t(.) %>%
image(1:100, 1:100,. , xlab="Movies", ylab="Users")
abline(h=0:100+0.5, v=0:100+0.5, col = "grey")
```

This matrix is quite sparse and shows that are a lot of missing ratings.
\newpage
Next, the distribution of ratings for movies and users is analyzed and displayed in logscale.

```{r Rating distributions, echo=FALSE}
p1 <- edx %>% 
     dplyr::count(movieId) %>% 
     ggplot(aes(n)) + 
     geom_histogram(bins = 25, color = "black") + 
     scale_x_log10() + 
     ggtitle("Movies")

p2 <- edx %>% 
     dplyr::count(userId) %>% 
     ggplot(aes(n)) + 
     geom_histogram(bins = 25, color = "black") + 
     scale_x_log10() + 
     ggtitle("Users")

grid.arrange(p1, p2, nrow = 1)
```

These graphs show that some movies are rated more than others and that some users rate more often than others, with the opposite being true as well.
\newpage
Let's compare how individual movies and users stack up vs. the average rating.

```{r avg rating, echo=FALSE}
mu <- mean(edx$rating) 
movie_avgs <- edx %>% 
  group_by(movieId) %>% 
  summarize(b_i = mean(rating - mu))
p3 <- movie_avgs %>% qplot(b_i, geom ="histogram", bins = 25, data = ., color = I("black")) + 
  ggtitle("Movies")

p4 <- edx %>% 
  group_by(userId) %>% 
  summarize(b_u = mean(rating)) %>% 
  filter(n()>=100) %>%
  ggplot(aes(b_u)) + 
  geom_histogram(bins = 25, color = "black") +
  ggtitle("Users")

grid.arrange(p3, p4, nrow = 1)
```

These graphs show that some movies receive higher ratings above/below the average than others and that some users rate higher/lower than the average for any given movie.
\newpage
It is apparent that there are user and movie effects, or biases, that can help build a good model. However, these biases must account for smaller sample sizes. A movie could have the highest rating, but have only been rated once. Taking it at face value would not help our model. Therefore, regularization will be used to penalize these smaller sample sizes. The formulas for movie effects and user effects are the following respectively, b_i = sum(rating - mu)/(n()+l) and b_u = sum(rating - b_i - mu)/(n()+l). Since the loss function was RMSE, the goal is to minimize it. The specific cut-off to achieve full credit is RMSE <= 0.87750.

The model uses cross validation to find the optimal penalty parameter, lambda, in the range of 0-10 by .25 that will minimize the RMSE.

```{r Final RMSE, warning=FALSE, echo=FALSE}
#RMSE function
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}

#Results Table
naive_rmse <- RMSE(edx$rating, mean(edx$rating))
rmse_results <- data_frame(method = "Just the Average", RMSE = naive_rmse)

#Regularized Movie & User Effect Model
#Using Cross Validation
lambdas <- seq(0, 10, 0.25)

rmses <- sapply(lambdas, function(l){
  
  mu <- mean(edx$rating)
  
  b_i <- edx %>% 
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu)/(n()+l))
  
  b_u <- edx %>% 
    left_join(b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mu)/(n()+l))
  
  predicted_ratings <- validation %>% 
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    mutate(pred = mu + b_i + b_u) %>%
    pull(pred)
  
  return(RMSE(predicted_ratings, validation$rating))
})

lambda <- lambdas[which.min(rmses)]
qplot(lambdas, rmses)
lambda
```
\newpage
# Results

```{r Results, echo=FALSE}
rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Regularized Movie + User Effect Model",  
                                     RMSE = min(rmses)))
rmse_results %>% knitr::kable()
```

The model performs significantly better than the baseline and is below the cut-off for full-credit.

#Conclusion
The training and validation datasets were provided. Exploratory data analysis revealed useful biases in movie and user ratings and by reason regularization was used since the sample sizes can be very small. Using these, a model was produced that meets the RMSE requirement.